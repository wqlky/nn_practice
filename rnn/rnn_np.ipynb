{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://github.com/krocki/dnc/blob/master/rnn-numpy.py    \n",
    "https://blog.csdn.net/tudaodiaozhale/article/details/80464060\n",
    "    \n",
    "    \n",
    "http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/     \n",
    "https://github.com/dennybritz/rnn-tutorial-rnnlm/blob/master/RNNLM.ipynb\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用numpy等基本库实现RNN\n",
    "\n",
    "# 公式\n",
    "## Notation\n",
    "输入序列：$x$   \n",
    "输出序列：$y$   \n",
    "输入，输出序列中的某个点: $ x^{<t>}, y^{<t>} $  \n",
    "输入，输出序列的长度: $ T_x^{(i)}, T_y^{(i)} $， 其中i表示第i个样本\n",
    "\n",
    "\n",
    "![rnn](rnn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## forward\n",
    "$$\n",
    "\\begin{align}\n",
    "a^{<t>} =& tanh( w_{aa}a^{<t-1>} + w_{ax}x^{<t>} + b_a )  \\\\\n",
    "\\\\\n",
    "\\hat y^{<t>} =& softmax(w_{ya}^{<t>} a^{<t>} + b_y) \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## loss\n",
    "$$\n",
    "\\begin{align}\n",
    "E^{<t>} = & - \\sum_i y_i^{<t>} ln \\hat y_i^{<t>} \\\\\n",
    "E(y, \\hat y) =& - \\sum_t E^{<t>} \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backpropagation\n",
    "\n",
    "### 对$w_{ya}, b_y$求导\n",
    "\n",
    "为了方便下面的推导，细化一下上面的forward公式。同时为了简化公式暂时省略$^{<t>}$\n",
    "$$\n",
    "\\begin{align}\n",
    "\\\\\n",
    "z =& w_{ya} a + b_y \\\\\n",
    "z_i =& \\sum_j w_{ya\\_ij} a_j + b_{y\\_i}  \\\\\n",
    "\\\\\n",
    "\\hat y_i =& \\frac{ e^{z_i} }{ \\sum_j e^{z_j} }  \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "损失函数：\n",
    "$$\n",
    "\\begin{align}\n",
    "E =& -\\sum_i y_i ln \\hat y_i  \\\\\n",
    "  =& -\\sum_i y_i ( z_i - ln \\sum_j e^{z_j}  ) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "求导\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{ \\partial E }{ \\partial w_{ya\\_ij} } =& \\sum_k \\frac{ \\partial E }{ \\partial z_k }\n",
    "                        \\frac{ \\partial z_k }{ \\partial w_{ya\\_ij}}   \\\\\n",
    "                                           =& \\frac{ \\partial E }{ \\partial z_i }\n",
    "                        \\frac{ \\partial z_i }{ \\partial w_{ya\\_ij}}                        \n",
    "\\\\\n",
    "\\\\\n",
    "\\frac{ \\partial E }{ \\partial z_i } =& \\frac{ \\partial ( -\\sum_{k \\neq i} y_k ( z_k - ln \\sum_j e^{z_j}  ) - y_i ( z_i - ln \\sum_j e^{z_j}  ) ) }{ \\partial z_i }  \\\\\n",
    "                                    =& -\\sum_{k \\neq i} y_k (0 - \\frac{e^{z_i}}{ \\sum_j e^{z_j} } ) - y_i (1 - \\frac{e^{z_i} }{ \\sum_j e^{z_j} } )  \\\\\n",
    "                                    =& \\sum_{k \\neq i} y_k \\frac{e^{z_i}}{ \\sum_j e^{z_j} } - y_i + \\frac{e^{z_i}}{ \\sum_j e^{z_j}}  \\\\\n",
    "                                    =& \\sum_k y_k \\frac{e^{z_i}}{ \\sum_j e^{z_j}} - y_i \\\\\n",
    "                                    =& \\frac{e^{z_i}}{ \\sum_j e^{z_j}} - y_i \\\\\n",
    "                                    =& \\hat y_i - y_i \\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\frac{ \\partial z_i }{ \\partial w_{ya\\_ij}} =& a_j\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "补上$^{<t>}$，得到\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{ \\partial E^{<t>} }{ \\partial z_i^{<t>} } =&  \\hat y_i^{<t>} - y_i^{<t>} \\\\\n",
    "\\\\\n",
    "\\frac{ \\partial E^{<t>} }{ \\partial w_{ya\\_ij} } =& a_j^{<t>}( \\hat y_i^{<t>} - y_i^{<t>} )  \\\\\n",
    "\\\\\n",
    "\\frac{ \\partial E^{<t>} }{ \\partial b_{y\\_i} } =& \\hat y_i^{<t>} - y_i^{<t>} \n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对$w_{aa}, w_{ax}, b_a$求导\n",
    "细化前向公式\n",
    "$$\n",
    "\\begin{align}\n",
    "s_i^{<t>} =& \\sum_j w_{aa\\_ij}a_j^{<t-1>} + \\sum_j w_{ax\\_ij}x_j^{<t>} + b_{a\\_i} \\\\\n",
    "a_i^{<t>} =& tanh( s_i^{<t>} )  \\\\\n",
    "\\\\\n",
    "z_i^{<t>} =& \\sum_j w_{ya\\_ij} a_j^{<t>} + b_{y\\_i}  \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对$w_{aa}$求导  \n",
    "在计算$\\frac{\\partial E^{<t>}}{\\partial w_{aa\\_ij}}$时需要考虑所有的$s_i^{<t'>}, 0<t' \\le t $\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{ \\partial E^{<t>} }{ \\partial w_{aa\\_ij} } =& \\sum_{t'} \\frac{\\partial E^{<t>}}{\\partial s_i^{<t'>}}\n",
    "                                                              \\frac{\\partial s_i^{<t'>}}{\\partial w_{aa\\_ij}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中第二项$\\frac{\\partial s_i^{<t'>}}{\\partial w_{aa\\_ij}}=a_j^{<t'-1>}$。    \n",
    "第一项计算比较复杂，下面采用递归的方式计算。当$0<t'<t$时：\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E^{<t>}}{\\partial s_i^{<t'>}} =& \\sum_k \\frac{\\partial E^{<t>}}{\\partial s_k^{<t'+1>}}\n",
    "                                                       \\frac{\\partial s_k^{<t'+1>}}{\\partial s_i^{<t'>}} \\\\\n",
    "=& \\sum_k \\sum_m \\frac{\\partial E^{<t>}}{\\partial s_k^{<t'+1>}}\n",
    "                 \\frac{\\partial s_k^{<t'+1>}}{\\partial a_m^{<t'>}}\n",
    "                 \\frac{\\partial a_m^{<t'>}}{\\partial s_i^{<t'>}}\\\\\n",
    "=& \\sum_k \\sum_m \\frac{\\partial E^{<t>}}{\\partial s_k^{<t'+1>}}\n",
    "                w_{aa_km} \\delta_{mi} ( 1-(a_i^{<t'>})^2 ) \\\\\n",
    "=& \\sum_k \\frac{\\partial E^{<t>}}{\\partial s_k^{<t'+1>}}\n",
    "                w_{aa_ki}( 1-(a_i^{<t'>})^2 ) \\\\\n",
    "=& \\sum_k w_{aa\\_ik}^T  \\frac{\\partial E^{<t>}}{\\partial s_k^{<t'+1>}} ( 1-(a_i^{<t'>})^2 ) \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "递推公式的初始值:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E^{<t>}}{ \\partial s_i^{<t>}} =& \\sum_m \\sum_n \\frac{ \\partial E^{<t>} }{ \\partial z_m^{<t>} } \n",
    "                                                       \\frac{ \\partial z_m^{<t>}}{ \\partial a_n^{<t>} }\n",
    "                                                       \\frac{ \\partial a_n^{<t>}}{ \\partial s_i^{<t>} } \\\\\n",
    "=& \\sum_m \\sum_n (\\hat y_i^{<t>} - y_i^{<t>}) w_{ya\\_mn} \\delta_{ni} ( 1 - (a_i^{<t>})^2 )\\\\ \n",
    "=& \\sum_m (\\hat y_i^{<t>} - y_i^{<t>}) w_{ya\\_mi} ( 1 - (a_i^{<t>})^2 )\\\\ \n",
    "=& \\sum_m w_{ya\\_im}^T(\\hat y_i^{<t>} - y_i^{<t>})( 1 - (a_i^{<t>})^2 )\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在算好$\\frac{\\partial E^{<t>}}{\\partial s_i^{<t>}}$后，就比较容易得到对$w_{ax}, b_a$的导数\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E^{<t>}}{\\partial w_{ax\\_ij}} =& \\sum_{t'} \\frac{\\partial E^{<t>}}{\\partial s_i^{<t'>}}\n",
    "                                                              \\frac{\\partial s_i^{<t'>}}{\\partial w_{ax\\_ij}} \\\\\n",
    "=& \\sum_{t'} \\frac{\\partial E^{<t>}}{\\partial s_i^{<t'>}} x_i^{<t'>}     \\\\                                       \n",
    "\\\\\n",
    "\\frac{\\partial E^{<t>}}{\\partial b_{a\\_i}} =& \\sum_{t'} \\frac{\\partial E^{<t>}}{\\partial s_i^{<t>}}\n",
    "                                                        \\frac{\\partial s_i^{<t>}}{\\partial b_{a\\_i}} \\\\\n",
    "=& \\sum_{t'} \\frac{\\partial E^{<t>}}{\\partial s_i^{<t'>}}    \\\\    \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵形式   \n",
    "\n",
    "对$w_{ya}, b_y$的导数\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{ \\partial E^{<t>} }{ \\partial w_{ya} } =& (\\hat y^{<t>} - y^{<t>} ) \\otimes a^{<t>}   \\\\\n",
    "\\\\\n",
    "\\frac{ \\partial E^{<t>} }{ \\partial b_y}  =& \\hat y^{<t>} - y^{<t>} \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial E^{<t>}}{\\partial s^{<t>}}$的递推公式：\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E^{<t>}}{ \\partial s^{<t>}} =& w_{ya}^T(\\hat y^{<t>} - y^{<t>}) * ( 1 - (a^{<t>})^2 )\\\\\n",
    "\\\\\n",
    "\\frac{\\partial E^{<t>}}{\\partial s^{<t'>}} =& w_{aa}^T \\frac{\\partial E^{<t>}}{\\partial s^{<t'+1>}} * ( 1-(a^{<t'>})^2 ) \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对$w_{aa}, w_{ax}, b_a$的导数\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E^{<t>}}{\\partial w_{aa}} =& \\sum_{t'} \\frac{\\partial E^{<t>}}{\\partial s^{<t'>}} \\otimes a^{<t'-1>}     \\\\                   \n",
    "\\frac{\\partial E^{<t>}}{\\partial w_{ax}} =& \\sum_{t'} \\frac{\\partial E^{<t>}}{\\partial s^{<t'>}} \\otimes x^{<t'>}\n",
    "\\\\\n",
    "\\frac{\\partial E^{<t>}}{\\partial b_a} =& \\sum_{t'} \\frac{\\partial E^{<t>}}{\\partial s^{<t'>}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp( x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "    def __init__(self, hid_dim, inp_dim, out_dim):\n",
    "        self.w_ax = np.random.uniform(-np.sqrt(1.0/inp_dim), np.sqrt(1.0/inp_dim), (hid_dim, inp_dim))\n",
    "        self.w_aa = np.random.uniform(-np.sqrt(1.0/hid_dim), np.sqrt(1.0/hid_dim), (hid_dim, hid_dim))\n",
    "        self.w_ya = np.random.uniform(-np.sqrt(1.0/hid_dim), np.sqrt(1.0/hid_dim), (out_dim, hid_dim))\n",
    "        self.b_a = np.zeros( (hid_dim,1), dtype=float )\n",
    "        self.b_y = np.zeros( (out_dim,1), dtype=float )\n",
    "        self.inp_dim = inp_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        T = len(x)\n",
    "        a = np.zeros( (T + 1, self.hid_dim), dtype=float )\n",
    "      \n",
    "        w_ax = self.w_ax\n",
    "        w_aa = self.w_aa\n",
    "        w_ya = self.w_ya\n",
    "        b_a = self.b_a\n",
    "        b_y = self.b_y\n",
    "        y_hat = zeros( (T, self.out_dim), dtype=float )\n",
    "        for t in range(T):\n",
    "            a[t] = np.tanh(np.dot(w_aa, a[t-1]) + np.dot(w_ax, x[t]) + b_a)\n",
    "            z = np.dot(w_ya, a[t]) + b_y\n",
    "            y_hat[t] = softmax(z)\n",
    "            \n",
    "        return [y_hat, a]\n",
    "            \n",
    "    def predict(self, x):\n",
    "        y_hat, _ = self.forward(x)\n",
    "        return np.argmax(y_hat, axis=1)\n",
    "    \n",
    "    def train(x, y, a_prev):\n",
    "        a = {}\n",
    "        a[-1] = np.copy(a_prev)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
