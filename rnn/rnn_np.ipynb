{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/krocki/dnc/blob/master/rnn-numpy.py\n",
    "https://blog.csdn.net/tudaodiaozhale/article/details/80464060\n",
    "    \n",
    "    \n",
    "http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/\n",
    "https://github.com/dennybritz/rnn-tutorial-rnnlm/blob/master/RNNLM.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用numpy等基本库实现RNN\n",
    "\n",
    "# 公式\n",
    "## Notation\n",
    "输入序列：$x, x^{<i>}$  \n",
    "输出序列：$y,y^{<i>}$\n",
    "输入，输出序列中的某个点: $ x^{<t>}, y^{<t>} $  \n",
    "输入，输出序列的长度: $ T_x^{(i)}, T_y^{(i)} $\n",
    "\n",
    "## forward\n",
    "$$\n",
    "a^{<t>} = tanh( w_{aa}a^{(t-1)} + w_{ax}x^{<t>} + b_a )  \\\\\n",
    "\\hat y = softmax(w_{ya}^{<t>} a^{<t>} + b_y)\n",
    "$$\n",
    "\n",
    "## loss\n",
    "$$\n",
    "E(y, \\hat y) = - \\sum_t y_t log \\hat y_t\n",
    "$$\n",
    "\n",
    "## backpropagation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp( x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "    def __init__(self, hid_dim, inp_dim, out_dim):\n",
    "        self.w_ax = np.random.uniform(-np.sqrt(1.0/inp_dim), np.sqrt(1.0/inp_dim), (hid_dim, inp_dim))\n",
    "        self.w_aa = np.random.uniform(-np.sqrt(1.0/hid_dim), np.sqrt(1.0/hid_dim), (hid_dim, hid_dim))\n",
    "        self.w_ya = np.random.uniform(-np.sqrt(1.0/hid_dim), np.sqrt(1.0/hid_dim), (out_dim, hid_dim))\n",
    "        self.b_a = np.zeros( (hid_dim,1), dtype=float )\n",
    "        self.b_y = np.zeros( (out_dim,1), dtype=float )\n",
    "        self.inp_dim = inp_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        T = len(x)\n",
    "        a = np.zeros( (T + 1, self.hid_dim), dtype=float )\n",
    "      \n",
    "        w_ax = self.w_ax\n",
    "        w_aa = self.w_aa\n",
    "        w_ya = self.w_ya\n",
    "        b_a = self.b_a\n",
    "        b_y = self.b_y\n",
    "        y_hat = zeros( (T, self.out_dim), dtype=float )\n",
    "        for t in range(T):\n",
    "            a[t] = np.tanh(np.dot(w_aa, a[t-1]) + np.dot(w_ax, x[t]) + b_a)\n",
    "            z = np.dot(w_ya, a[t]) + b_y\n",
    "            y_hat[t] = softmax(z)\n",
    "            \n",
    "        return [y_hat, a]\n",
    "            \n",
    "    def predict(self, x):\n",
    "        y_hat, _ = self.forward(x)\n",
    "        return np.argmax(y_hat, axis=1)\n",
    "    \n",
    "    def train(x, y, a_prev):\n",
    "        a = {}\n",
    "        a[-1] = np.copy(a_prev)\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
